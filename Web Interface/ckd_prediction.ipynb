{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFse_LJzWNTs"
      },
      "source": [
        "# Step 1: Prepare a dataset filled missing values with mean and mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Sample DataFrame (replace with your data)\n",
        "\n",
        "df = pd.read_csv('/workspaces/Chronic-Kidney-Disease/Data files/df_features_selected.csv')\n",
        "\n",
        "\n",
        "for column in df.columns:\n",
        "    if df[column].dtype in ['int64', 'float64']:  # Numerical column → mean\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "    else:  # Categorical column → mode\n",
        "        imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df[column] = imputer.fit_transform(df[[column]]).ravel()\n",
        "\n",
        "encoding_rules = {\n",
        "    # Binary encoding (yes->1, no->0)\n",
        "    'hypertension': {'yes': 1, 'no': 0},  # Hypertension\n",
        "    'diabetes mellitus': {'yes': 1, 'no': 0},    # Diabetes Mellitus\n",
        "    'coronary artery disease': {'yes': 1, 'no': 0},   # Coronary Artery Disease\n",
        "    'appetite': {'good': 0, 'poor': 1},\n",
        "    'pedal edema': {'yes': 1, 'no': 0},    # Pedal Edema\n",
        "    'anemia': {'yes': 1, 'no': 0},   # Anemia\n",
        "    'ckd or not ckd': {'ckd': 1, 'notckd': 0}  # Target variable\n",
        "}\n",
        "\n",
        "# Apply encoding\n",
        "for column, mapping in encoding_rules.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].map(mapping).astype('float64')\n",
        "\n",
        "\n",
        "\n",
        "#df.to_csv(\"df_filled.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Try to input a data to evaluate using the best conditions found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "fMNRFY7UP_m6",
        "outputId": "01a87492-01ec-4667-cac7-e281a485d47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "High Sensitivity Voting Classifier\n",
            "Diagnosis: [ True] \n",
            "Index: 0.9056489909061978\n",
            "Full Ensemble Voting Classifier\n",
            "Diagnosis: [ True] \n",
            "Index: 0.836547408235852\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('df_filled.csv')\n",
        "#user data\n",
        "data = {\n",
        "    'age': [30],\n",
        "    'hypertension': [1],\n",
        "    'diabetes mellitus': [0],\n",
        "    'coronary artery disease': [0],\n",
        "    'appetite': [0],\n",
        "    'anemia': [0],\n",
        "    'pedal edema': [0]\n",
        "}\n",
        "df_user = pd.DataFrame(data)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "df['age']=scaler.fit_transform(df[['age']])\n",
        "df_user['age']=scaler.transform(df_user[['age']])\n",
        "X=df.drop(['ckd or not ckd'],axis=1)\n",
        "y=df['ckd or not ckd']\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "models = {\n",
        "    'RandomForestClassifier': RandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        class_weight='balanced',\n",
        "        criterion='gini',\n",
        "        max_depth=None,\n",
        "        max_features='sqrt',\n",
        "        min_samples_leaf=2,\n",
        "        min_samples_split=5,\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier(\n",
        "        bootstrap=True,\n",
        "        class_weight='balanced',\n",
        "        criterion='gini',\n",
        "        max_depth=None,\n",
        "        max_features='sqrt',\n",
        "        min_samples_leaf=2,\n",
        "        min_samples_split=5,\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(\n",
        "        criterion='friedman_mse',\n",
        "        learning_rate=0.01,\n",
        "        max_depth=5,\n",
        "        max_features='sqrt',\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        n_estimators=100,\n",
        "        subsample=0.8,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(\n",
        "        estimator=DecisionTreeClassifier(max_depth=2),\n",
        "        learning_rate=1.0,\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'GaussianNB': GaussianNB(\n",
        "        var_smoothing=1e-11\n",
        "    ),\n",
        "    'LogisticRegression': LogisticRegression(\n",
        "        C=1,\n",
        "        class_weight='balanced',\n",
        "        max_iter=1000,\n",
        "        penalty='l2',\n",
        "        solver='lbfgs',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(\n",
        "        ccp_alpha=0.0,\n",
        "        class_weight='balanced',\n",
        "        criterion='gini',\n",
        "        max_depth=None,\n",
        "        max_features='sqrt',\n",
        "        min_samples_leaf=2,\n",
        "        min_samples_split=2,\n",
        "        splitter='best',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'SVC': SVC(\n",
        "        C=10,\n",
        "        class_weight='balanced',\n",
        "        degree=2,\n",
        "        gamma='scale',\n",
        "        kernel='rbf',\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'XGBClassifier': XGBClassifier(\n",
        "        colsample_bytree=0.8,\n",
        "        learning_rate=0.01,\n",
        "        max_depth=3,\n",
        "        min_child_weight=1,\n",
        "        n_estimators=100,\n",
        "        objective='binary:logistic',\n",
        "        subsample=0.8,\n",
        "        tree_method='auto',\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    ),\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(\n",
        "        algorithm='auto',\n",
        "        leaf_size=30,\n",
        "        n_neighbors=3,\n",
        "        weights='uniform'\n",
        "    )\n",
        "}\n",
        "\n",
        "tier1_clf = VotingClassifier(\n",
        "    estimators=[('GaussianNB', models['GaussianNB']), ('LogisticRegression', models['LogisticRegression'])],\n",
        "    voting='soft'  # Weighted probability average\n",
        ")\n",
        "\n",
        "tier1_clf.fit(X, y)\n",
        "result = [tier1_clf.predict(df_user),tier1_clf.predict_proba(df_user)]\n",
        "print(\"High Sensitivity Voting Classifier\\nDiagnosis:\",(result[0] == float(1)),\"\\nIndex:\",result[1].reshape(-1)[1])\n",
        "\n",
        "tier2_clf = VotingClassifier(\n",
        "    estimators=[(name, clone(model)) for name, model in models.items()],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "tier2_clf.fit(X, y)\n",
        "result = [tier2_clf.predict(df_user),tier2_clf.predict_proba(df_user)]\n",
        "print(\"Full Ensemble Voting Classifier\\nDiagnosis:\",(result[0] == float(1)),\"\\nIndex:\",result[1].reshape(-1)[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
